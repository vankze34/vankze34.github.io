<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator>
  <link href="http://localhost:4000/tag/machinelearning/feed.xml" rel="self" type="application/atom+xml" />
  <link href="http://localhost:4000/" rel="alternate" type="text/html" />
  <updated>2021-11-19T16:31:34+09:00</updated>
  <id>http://localhost:4000/tag/machinelearning/feed.xml</id>

  
  
  

  
    <title type="html">Vans DS Gym | </title>
  

  
    <subtitle>데이터 사이언스 훈련장</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">Chapter02 - 04. Model Selection 모듈 소개 (2)</title>
      <link href="http://localhost:4000/ml-ch02-04_2" rel="alternate" type="text/html" title="Chapter02 - 04. Model Selection 모듈 소개 (2)" />
      <published>2021-11-19T00:00:00+09:00</published>
      <updated>2021-11-19T00:00:00+09:00</updated>
      <id>http://localhost:4000/ml-ch02-04_2</id>
      <content type="html" xml:base="http://localhost:4000/ml-ch02-04_2">&lt;h3 id=&quot;교차-검증&quot;&gt;교차 검증&lt;/h3&gt;

&lt;p&gt;과적합(Overfitting)이란 모델이 학습 데이터에만 과도하게 최적화되어 실제 예측 성능이 과도하게 떨어지는 것을 말한다. 과적합이라는 문제점을 개선하기 위해 교차 검증을 수행한다.&lt;/p&gt;

&lt;p&gt;교차 검증은 본고사를 치르기 전에 모의고사를 여러번 보는 것과 같다. 이상치, 분포도, 다향한 속성값, 피처 중요도 등 여러 영향에 의해 생기는 데이터 편중을 막기 위해서 &lt;strong&gt;별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것&lt;/strong&gt;이다.&lt;/p&gt;

&lt;h4 id=&quot;k폴드-교차-검증&quot;&gt;K폴드 교차 검증&lt;/h4&gt;

&lt;p&gt;가장 보편적으로 사용되는 교차 검증 기법이다.&lt;/p&gt;

&lt;p&gt;K개의 데이터 폴드 세트를 만들고 K번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 방법이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/built/images/ml/2021-11-17-ml-ch02-01.png&quot; alt=&quot;K폴드&quot; /&gt;&lt;/p&gt;

&lt;p&gt;사이키런에서는 K 폴드 교차 검증 프로세스를 구현하기 위해 KFold와 StratifiedKFold 클래스를 제공한다.&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.tree&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KFold&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dt_clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;156&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kfold&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KFold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_splits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cv_accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;붓꽃 데이터 세트 크기:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;p&gt;【Output】&lt;/p&gt;

&lt;p&gt;붓꽃 데이터 세트 크기: 150&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;전체 붓꽃 데이터는 모두 150개이기 때문에 학습용 데이터 세트는 120개, 검증 테스트 데이터 세트는 30개로 분할된다.
KFold객체는 split()을 호출하면 학습용/검증용 데이터로 분할할 수 있는 인덱스를 반환한다.&lt;/p&gt;

&lt;p&gt;다음의 예제를 통해 교차 검증 수행 시마다 학습과 검증을 반복해본다.&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# KFold객체의 split( ) 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환  
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt;  &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kfold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#학습 및 예측 
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dt_clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt_clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 반복 시 마다 정확도 측정 
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}&apos;&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;#{0} 검증 세트 인덱스:{1}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cv_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;span class=&quot;c1&quot;&gt;# 개별 iteration별 정확도를 합하여 평균 정확도 계산 
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;## 평균 검증 정확도:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;p&gt;【Output】&lt;/p&gt;

&lt;p&gt;#1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30
#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]&lt;/p&gt;

&lt;p&gt;#2 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30
#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
 54 55 56 57 58 59]&lt;/p&gt;

&lt;p&gt;#3 교차 검증 정확도 :0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30
#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
 84 85 86 87 88 89]&lt;/p&gt;

&lt;p&gt;#4 교차 검증 정확도 :0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30
#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119]&lt;/p&gt;

&lt;p&gt;#5 교차 검증 정확도 :0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30
#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
 138 139 140 141 142 143 144 145 146 147 148 149]&lt;/p&gt;

&lt;p&gt;##평균 검증 정확도: 0.9&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;stratified-k-폴드&quot;&gt;Stratified K 폴드&lt;/h4&gt;

&lt;p&gt;불균형한(imbalanced) 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K 폴드 방식이다.&lt;/p&gt;

&lt;p&gt;예) 대출 사기 데이터 예측
데이터 세트 = 1억 건
수십개의 feature와 대출 사기 여부를 뜻하는 레이블(사기: 1, 정상: 0)로 구성되어있다. 그런데 대부분의 데이터는 정상 대출 일 것이다.
0.0001%의 작은 확률로 대출 사기 레이블이 존재한다면 K폴드로 랜덤하게 학습/테스트 세트 인덱스를 고르더라도 제대로 반영이 안되는 경우가 쉽게 발생한다.&lt;/p&gt;

&lt;p&gt;Stratified K 폴드는 원본 데이터의 레이블 분포를 먼저 고려한 뒤 이 분포와 동일하게 학습과 검증 데이터 세트를 분배한다.&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feature_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;label&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;label&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;【Output】&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;2      50 &lt;br /&gt;
1      50 &lt;br /&gt;
0      50&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;레이블 값은 0, 1, 2 모두 50개로 동일하다.
Setosa, Versicolor, Virginica 모두 50개 인 것이다.
이슈가 발생하는 현상을 도출하기 위해 3개의 폴드 세트를 KFold로 생성하고 각 교차 검증 시마다 생성되는 학습/검증 레이블 데이터 값의 분포도를 확인해보자.&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;kfold&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KFold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_splits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kfold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;label_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;label&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;label_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;label&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;## 교차 검증: {0}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;학습 레이블 데이터 분포:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;검증 레이블 데이터 분포:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;【Output】&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;## 교차 검증: 1 &lt;br /&gt;
학습 레이블 데이터 분포: &lt;br /&gt;
 2    50 &lt;br /&gt;
1    50 &lt;br /&gt;
검증 레이블 데이터 분포: &lt;br /&gt;
 0    50 &lt;br /&gt;
## 교차 검증: 2 &lt;br /&gt;
학습 레이블 데이터 분포: &lt;br /&gt;
 2    50 &lt;br /&gt;
0    50 &lt;br /&gt;
검증 레이블 데이터 분포: &lt;br /&gt;
 1    50 &lt;br /&gt;
## 교차 검증: 3 &lt;br /&gt;
학습 레이블 데이터 분포: &lt;br /&gt;
 1    50 &lt;br /&gt;
0    50 &lt;br /&gt;
검증 레이블 데이터 분포: &lt;br /&gt;
 2    50 &lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;교차검증: 1의 경우는 학습 레이블로 1, 2 값이 각각 50개가 추출되고 검증 레이블로 0이 50개 추출되었다. 학습 레이블로는 1, 2밖에 없으므로 0의 경우는 전혀 학습하지 못한다. 반대로 검증 레이블은 0 밖에 없으므로 학습 모델은 0을 예측하지 못한다. 이런 방법으로 데이터 세트를 분할하면 검증 예측도는 0이 될 수 밖에 없다.&lt;/p&gt;

&lt;p&gt;StratifiedFold는 이렇게 KFold로 분할된 레이블 데이터 세트가 전체 레이블 값의 분포도를 반영하지 못하는 문제를 해결 할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StratifiedFold&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;skf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StratifiedFold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_splits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;label&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;label_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;label&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;label_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;label&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;## 교차 검증: {0}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;학습 레이블 데이터 분포:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;검증 레이블 데이터 분포:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;【Output】&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;## 교차 검증: 1 &lt;br /&gt;
학습 레이블 데이터 분포:  &lt;br /&gt;
 2    33 &lt;br /&gt;
1    33 &lt;br /&gt;
0    33 &lt;br /&gt;
검증 레이블 데이터 분포: &lt;br /&gt;
 2    17 &lt;br /&gt;
1    17 &lt;br /&gt;
0    17 &lt;br /&gt;
## 교차 검증: 2 &lt;br /&gt;
학습 레이블 데이터 분포: &lt;br /&gt;
 2    33 &lt;br /&gt;
1    33 &lt;br /&gt;
0    33 &lt;br /&gt;
검증 레이블 데이터 분포: &lt;br /&gt;
 2    17 &lt;br /&gt;
1    17 &lt;br /&gt;
0    17 &lt;br /&gt;
## 교차 검증: 3 &lt;br /&gt;
학습 레이블 데이터 분포: &lt;br /&gt;
 2    34 &lt;br /&gt;
1    34 &lt;br /&gt;
0    34 &lt;br /&gt;
검증 레이블 데이터 분포: &lt;br /&gt;
 2    16 &lt;br /&gt;
1    16 &lt;br /&gt;
0    16 &lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;출력 결과를 보면 학습 레이블과 검증 레이블 데이터 값의 분포도가 동일하게 할당 되었음을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;다음은 붓꽃 데이터를 StratifiedKFold를 이용해 학습/검증해 본다.&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;dt_clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;156&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;skfold&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StratifiedKFold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_splits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cv_accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# StratifiedKFold의 split( ) 호출시 반드시 레이블 데이터 셋도 추가 입력 필요  
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt;  &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skfold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#학습 및 예측 
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dt_clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt_clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 반복 시 마다 정확도 측정 
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}&apos;&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;#{0} 검증 세트 인덱스:{1}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cv_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;span class=&quot;c1&quot;&gt;# 교차 검증별 정확도 및 평균 정확도 계산 
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;## 교차 검증별 정확도:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;## 평균 검증 정확도:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;【Output】&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;#1 교차 검증 정확도 :0.9804, 학습 데이터 크기: 99, 검증 데이터 크기: 51 &lt;br /&gt;
#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50
  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101
 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116]&lt;/p&gt;

&lt;p&gt;#2 교차 검증 정확도 :0.9216, 학습 데이터 크기: 99, 검증 데이터 크기: 51 &lt;br /&gt;
#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67
  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83 117 118
 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133]&lt;/p&gt;

&lt;p&gt;#3 교차 검증 정확도 :0.9792, 학습 데이터 크기: 102, 검증 데이터 크기: 48 &lt;br /&gt;
#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  84  85
  86  87  88  89  90  91  92  93  94  95  96  97  98  99 134 135 136 137
 138 139 140 141 142 143 144 145 146 147 148 149]&lt;/p&gt;

&lt;p&gt;## 교차 검증별 정확도: [0.9804 0.9216 0.9792]&lt;/p&gt;

&lt;p&gt;## 평균 검증 정확도: 0.9604&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;3개의 Stratified K 폴드로 교차 검증한 결과 평균 검증 정확도가 약 96.04%로 측정되었다. 일반적인 분류(Classification)에서의 교차 검증은 K 폴드가 아니라 Stratified K 폴드로 분할되어야 한다.&lt;/p&gt;

&lt;p&gt;하지만 회귀(Regression)에서는 Stratified K 폴드가 지원되지 않는다. 그 이유는 회귀의 결정값은 이산값 형태의 레이블이 아니라 연속된 숫자값이기 때문에 결정값별로 분포를 정하는 의미가 없기 때문이다.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Jaekwang Van</name>
        
        
      </author>

      

      
        <category term="machinelearning" />
      

      
        <summary type="html">교차 검증</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Chapter02 - 04. Model Selection 모듈 소개 (1)</title>
      <link href="http://localhost:4000/ml-ch02-04_1" rel="alternate" type="text/html" title="Chapter02 - 04. Model Selection 모듈 소개 (1)" />
      <published>2021-11-18T00:00:00+09:00</published>
      <updated>2021-11-18T00:00:00+09:00</updated>
      <id>http://localhost:4000/ml-ch02-04_1</id>
      <content type="html" xml:base="http://localhost:4000/ml-ch02-04_1">&lt;h3 id=&quot;학습테스트-데이터-셋-분리---train_test_split&quot;&gt;학습/테스트 데이터 셋 분리 - train_test_split()&lt;/h3&gt;

&lt;h4 id=&quot;붓꽃-데이터-세트를-테스트학습--3070-으로-분리&quot;&gt;붓꽃 데이터 세트를 테스트:학습 = 30:70 으로 분리&lt;/h4&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.tree&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_iris&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dt_clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iris_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;121&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;test_size: 전체 데이터에서 테스트 데이터 셋의 크기를 얼마로 샘플링 할 것인가를 결정한다. 디폴트는 0.25&lt;/li&gt;
  &lt;li&gt;train_size: 전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링 할 것인가를 결정한다. test_size를 사용하기에 잘 사용되지 않음&lt;/li&gt;
  &lt;li&gt;shuffle: 데이터를 분리하기 전에 미리 섞을지 결정한다. 디폴트는 True&lt;/li&gt;
  &lt;li&gt;random_state: 호출할 때마다 동일한 학습/테스트용 데이터 셋을 생성하기 위해 주어지는 난수 값이다.&lt;/li&gt;
  &lt;li&gt;train_test_split()의 반환값: tuple&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;정확도-측정&quot;&gt;정확도 측정&lt;/h4&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;dt_clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt_clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;예측 정확도: {0:.4f}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;p&gt;【Output】&lt;/p&gt;

&lt;p&gt;예측 정확도: 0.9556&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jaekwang Van</name>
        
        
      </author>

      

      
        <category term="machinelearning" />
      

      
        <summary type="html">학습/테스트 데이터 셋 분리 - train_test_split()</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Chapter02 - 03. 사이킷런의 기반 프레임워크 익히기</title>
      <link href="http://localhost:4000/ml-ch02-03" rel="alternate" type="text/html" title="Chapter02 - 03. 사이킷런의 기반 프레임워크 익히기" />
      <published>2021-11-18T00:00:00+09:00</published>
      <updated>2021-11-18T00:00:00+09:00</updated>
      <id>http://localhost:4000/ml-ch02-03</id>
      <content type="html" xml:base="http://localhost:4000/ml-ch02-03">&lt;h3 id=&quot;estimator-이해-및-fit-predict-메서드&quot;&gt;Estimator 이해 및 fit(), predict() 메서드&lt;/h3&gt;

&lt;p&gt;분류(Classifier)와 회귀(Regression)와 같은 지도학습의 모든 알고리즘을 사이킷런에서는 Estimator라고 부른다. Estimator 클래스에는 fit()와 predict()를 포함한다.&lt;/p&gt;

&lt;p&gt;비지도학습인 차원 축소, 클러스터링, 피처 추출등을 구현한 클래스는 fit()과 tarnsform()을 적용한다. 비지도의 fit()은 지도학습에서 이루어지는 학습을 의미하는 것이 아니라 입력 데이터 형태에 맞춰 데이터를 변환하기 위한 사전 구조를 맞추는 작업이다. 그리고 실제 작업은 transform()을 통해 이루어진다.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Jaekwang Van</name>
        
        
      </author>

      

      
        <category term="machinelearning" />
      

      
        <summary type="html">Estimator 이해 및 fit(), predict() 메서드</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Chapter02 - 01. 사이킷런 소개와 특징</title>
      <link href="http://localhost:4000/ml-ch02-01" rel="alternate" type="text/html" title="Chapter02 - 01. 사이킷런 소개와 특징" />
      <published>2021-11-17T00:00:00+09:00</published>
      <updated>2021-11-17T00:00:00+09:00</updated>
      <id>http://localhost:4000/ml-ch02-01</id>
      <content type="html" xml:base="http://localhost:4000/ml-ch02-01">&lt;p&gt;사이킷런(scikit-learn)은 오랜 기간 파이썬 세계에서 대표적인 머신러닝 라이브러리로 인정받았다.&lt;/p&gt;

&lt;p&gt;※ 사이킷런의 특징&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;가장 파이썬스러운 API 제공&lt;/li&gt;
  &lt;li&gt;매우 다양한 알고리즘과 편리한 프레임워크와 API제공&lt;/li&gt;
  &lt;li&gt;오랜 기간 검증되었고 많은 환경에서 사용되는 성숙한 라이브러리&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(base) VANKZE34:~ van$ python
Python 3.8.3 (default, Jul  2 2020, 11:26:31) 
[Clang 10.0.0 ] :: Anaconda, Inc. on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sklearn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__version__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;p&gt;【Output】&lt;/p&gt;

&lt;p&gt;0.24.2&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jaekwang Van</name>
        
        
      </author>

      

      
        <category term="machinelearning" />
      

      
        <summary type="html">사이킷런(scikit-learn)은 오랜 기간 파이썬 세계에서 대표적인 머신러닝 라이브러리로 인정받았다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">1장 컴퓨터는 데이터에서 배운다</title>
      <link href="http://localhost:4000/ml-ch01-01_bk" rel="alternate" type="text/html" title="1장 컴퓨터는 데이터에서 배운다" />
      <published>2021-11-17T00:00:00+09:00</published>
      <updated>2021-11-17T00:00:00+09:00</updated>
      <id>http://localhost:4000/ml-ch01-01_bk</id>
      <content type="html" xml:base="http://localhost:4000/ml-ch01-01_bk">&lt;h3 id=&quot;여기서-다루는-것들&quot;&gt;여기서 다루는 것들&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;머신 러닝의 일반적 개념 이해하기&lt;/li&gt;
  &lt;li&gt;세 종류의 학습과 기본 용어 알아보기&lt;/li&gt;
  &lt;li&gt;성공적인 머신 러닝 시스템을 설계하는 수 요소 알아보기&lt;/li&gt;
  &lt;li&gt;데이터 분석과 머신 러닝을 위한 파이썬을 설치하고 설정하기&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;11-데이터를-지식으로-바꾸는-지능적인-시스템-구축&quot;&gt;1.1 데이터를 지식으로 바꾸는 지능적인 시스템 구축&lt;/h3&gt;
&lt;hr /&gt;

&lt;p&gt;비정형 데이터가 풍부한 현대시대에 효율적으로 지식을 추출하여 예측 모델과 데이터 기반의 의사 결정 성능을 향상시키는 머신러닝은 점점 중요해 지고 있다.
최근에는 딥러닝 모델을 사용해서 여러 해결하기 어려웠던 문제들을 해결하고 잇다.&lt;/p&gt;

&lt;h3 id=&quot;12-머신러닝의-세-가지-종류&quot;&gt;1.2 머신러닝의 세 가지 종류&lt;/h3&gt;

&lt;p&gt;1) 지도학습 (supervised learning)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;레이블된 데이터&lt;/li&gt;
  &lt;li&gt;직접 피드백&lt;/li&gt;
  &lt;li&gt;출력 및 미래 예측&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2) 비지도학습 (unsupervised learning)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;레이블 및 타깃 없음&lt;/li&gt;
  &lt;li&gt;피드백 없음&lt;/li&gt;
  &lt;li&gt;데이터에서 숨겨진 구조 찾기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;3) 강화학습 (reinforcement learning)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;결정 과정&lt;/li&gt;
  &lt;li&gt;보상 시스템&lt;/li&gt;
  &lt;li&gt;연속된 행동에서 학습&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;121-지도학습으로-미래-예측&quot;&gt;1.2.1 지도학습으로 미래 예측&lt;/h4&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;훈련데이터 → 머신러닝 알고리즘 → 예측 모델 → 예측

                                ↑

                        새로운 데이터
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;분류-클래스-레이블-예측&quot;&gt;분류: 클래스 레이블 예측&lt;/h5&gt;

&lt;p&gt;예) 스팸 메일 분류&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;훈련된 데이터에는 이메일이 스팸인지 아닌지 레이블링 되어있음&lt;/li&gt;
  &lt;li&gt;새로운 이메일을 스팸인지 아닌지 지도학습을 이용하여 &lt;strong&gt;분류 (classification)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위에서 언급한 스펨 메일 분류는 &lt;strong&gt;이진 분류(binary classification)&lt;/strong&gt; 작업의 대표적인 예이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/built/images/ml/2021-11-17-ml-ch01-01.png&quot; alt=&quot;결정 경계&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림은 2차원 데이터 셋의 샘플들을 두개의 클래스로 구분하는 규칙을 학습하여 경정 경계(decision boundary)라는 선이 나타나 이진 분류한 경우에 해당한다.&lt;/p&gt;

&lt;p&gt;또한 두개 이상의 클래스 레이블을 가진 경우의 분류는 다중 분류(multiclass classification)이라고 한다.
대표적인 예로는 &lt;strong&gt;손으로 쓴 글자 인식&lt;/strong&gt;이다.&lt;/p&gt;

&lt;h5 id=&quot;회귀-연속적인-출력-값-예측&quot;&gt;회귀: 연속적인 출력 값 예측&lt;/h5&gt;

&lt;blockquote&gt;
  &lt;p&gt;회귀는 &lt;strong&gt;예측 변수(predictor variable) 또는 설명 변수(explanatory variable)&lt;/strong&gt;와 연속적인 &lt;strong&gt;반응 변수(response variable) 또는 결과(outcome)&lt;/strong&gt;가 주어졌을 때 출력 값을 예측하기 위해 두 변수 사이의 관계를 찾는 것이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;머신러닝 분야에서는 에측 변수를 보통 “특성(feature)”이라고 부르고 반응 변수를 “타깃(target”이라고 부른다.&lt;/p&gt;

&lt;p&gt;예) 학생들의 수학 SAT 점수 예측&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;x(시험 공부에 투자한 시간)과 y(최종 점수) 사이의 관계가 있다고 가정&lt;/li&gt;
  &lt;li&gt;두 x, y를 훈련 데이터로 만들고 학습하여 예측&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/built/images/ml/2021-11-17-ml-ch01-02.png&quot; alt=&quot;선형 회귀&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림과 같이 특성 x와 타깃 y가 주어지면 데이터 포인트와 직선 사이의 거리가 최소화 되는 직선을 긋고, 직선의 기울기와 절편을 사용하여 새로운 데이터의 출력 값을 에측한다.&lt;/p&gt;

&lt;h4 id=&quot;122-강화-학습으로-반응형-문제-해결&quot;&gt;1.2.2 강화 학습으로 반응형 문제 해결&lt;/h4&gt;

&lt;p&gt;머신러닝의 또 다른 종류인 &lt;strong&gt;강화학습&lt;/strong&gt;은 환경(에이전트)과 상호 작용하여 시스템의 성능을 향상시키는 것이 목적이다.&lt;/p&gt;

&lt;p&gt;강화학습의 피드백은 정답(ground truth) 레이블이나 값이 아니다.&lt;/p&gt;

&lt;p&gt;보상 함수로 얼마나 행동이 좋은지를 측정한 값이다.&lt;/p&gt;

&lt;p&gt;예) 체스 게임&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;에이전트는 체스판의 상태(환경)에 따라 기물의 이동을 결정&lt;/li&gt;
  &lt;li&gt;보상은 게임을 종료했을 때 승리하거나 패배하는 것으로 정의&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/built/images/ml/2021-11-17-ml-ch01-03.png&quot; alt=&quot;강화 학습&quot; /&gt;&lt;/p&gt;

&lt;p&gt;강화 학습에는 여러 하위 분류가 있다.&lt;/p&gt;

&lt;p&gt;일반적으로는 학습 에이전트가 환경과 상호 작용하여 보상을 최대화 하는 것이다. 예를들어 상대 체스 기물을 잡거나 퀸을 위협하는 것이다.&lt;/p&gt;

&lt;p&gt;반면 어떤 위치는 게임에 질 가능성이 높은 상태와 연관된다. 예를들어 다음 턴에 상대로부터 기물을 잃게 되는 경우이다.&lt;/p&gt;

&lt;p&gt;체스 게임에서 보상(승: +, 패: -)은 게임이 끝날 때까지 주어지지 않는다. 그리고 최종 보상은 상대의 플레이 방식에 따라 다르다. 예를들어 상대로부터 퀸을 잃었지만 게임에서 승리한 경우이다.&lt;/p&gt;

&lt;p&gt;강화 학습은 행동을 수행하고 피드백을 통해 얻은 전체 보상을 최대화하는 일련의 행동을 학습하는 것이다.&lt;/p&gt;

&lt;h4 id=&quot;123-비지도-학습으로-숨겨진-구조-발견&quot;&gt;1.2.3 비지도 학습으로 숨겨진 구조 발견&lt;/h4&gt;

&lt;p&gt;지도 학습에서는 훈련시에 정답을 알고 있고, 강화 학습에서는 에이전트의 특정 행동을 보상하는 방식이지만, 비지도 학습에서는 레이블되지 않거나 구조를 할 수 없는 데이터를 다룬다. 비지도 학습 기법을 사용하면&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Jaekwang Van</name>
        
        
      </author>

      

      
        <category term="machinelearning" />
      

      
        <summary type="html">여기서 다루는 것들 머신 러닝의 일반적 개념 이해하기 세 종류의 학습과 기본 용어 알아보기 성공적인 머신 러닝 시스템을 설계하는 수 요소 알아보기 데이터 분석과 머신 러닝을 위한 파이썬을 설치하고 설정하기</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Chapter02 - 02 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기</title>
      <link href="http://localhost:4000/ml-ch02-02" rel="alternate" type="text/html" title="Chapter02 - 02 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기" />
      <published>2021-11-17T00:00:00+09:00</published>
      <updated>2021-11-17T00:00:00+09:00</updated>
      <id>http://localhost:4000/ml-ch02-02</id>
      <content type="html" xml:base="http://localhost:4000/ml-ch02-02">&lt;p&gt;분류(Classification)는 대표적인 지도학습(Supervised Learning) 방법의 하나이다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;새로운 주피터 노트북 생성&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;사이킷런에서 사용할 모듈 임포트&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;의사 결정 트리를 ML 알고리즘: DecisionTreeClassifier&lt;/li&gt;
      &lt;li&gt;데이터 세트 분리(학습, 테스트): train_test_split() 함수&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 붓꽃 데이터 세트를 로딩합니다. 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# iris.data는 Iris 데이터 세트에서 피처(feature)만으로 된 데이터를 numpy로 가지고 있습니다. 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# iris.target은 붓꽃 데이터 세트에서 레이블(결정 값) 데이터를 numpy로 가지고 있습니다. 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris_label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;iris target값:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris_label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;iris target명:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환합니다. 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feature_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;label&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iris_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;p&gt;【Output】&lt;/p&gt;

&lt;p&gt;iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2]
iris target명: [‘setosa’ ‘versicolor’ ‘virginica’]&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;sepal length (cm)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;sepal width (cm)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;petal length (cm)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;petal width (cm)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;label&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;
&lt;p&gt;feature에는 sepal length, sepal width, petal length, petal width가 있다. 레이블(Label, 결정값)은 0, 1, 2 세 종류의 값으로 되어 있으며 0: Setosa, 1: versicolor, 2: virginica를 의미한다.&lt;/p&gt;

&lt;h3 id=&quot;학습용-데이터와-테스트용-데이터를-분리&quot;&gt;학습용 데이터와 테스트용 데이터를 분리&lt;/h3&gt;

&lt;p&gt;학습용 데이터와 테스트용 데이터는 반드시 분리해야 된다.
학습된 모델이 얼마나 뛰어난 성능을 갖는지 평가하기 위해서이다.
사이킷 런에서 제공하는 train_test_split()을 이용하여 분리.&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris_label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;random_state는 호출할 때 마다 지정된 seed에 의해 일정한 데이터로 분리하기 위해서 사용한다. 지정하지 않으면 매번 랜덤으로 분리된다.&lt;/p&gt;

&lt;h3 id=&quot;의사-결정-트리를-이용해-학습과-예측을-수행&quot;&gt;의사 결정 트리를 이용해 학습과 예측을 수행&lt;/h3&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# DecisionTreeClassifier 객체 생성
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dt_clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 학습 수행
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;학습이 완료되었다.&lt;/p&gt;

&lt;p&gt;예측은 반드시 학습 데이터에서 사용한 적이 없는 데이터를 사용해야 하며, 일반적으로는 테스트 데이터 셋을 이용한다. 위에서 분리한 테스트 데이터를 이용하자.&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt_clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;성능 평가를 해보자. 정확도는 예측 결과가 실제 레이블 값과 얼마나 정확하게 맞는지를 평가하는 지표이다. 정확도 측정을 위해 accuracy_score()함수 사용&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;예측 정확도: {0:.4f}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;p&gt;【Output】&lt;/p&gt;

&lt;p&gt;예측 정확도: 0.9333&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;예측-프로세스-정리&quot;&gt;예측 프로세스 정리&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;데이터 셋 분리&lt;/li&gt;
  &lt;li&gt;모델 학습&lt;/li&gt;
  &lt;li&gt;예측 수행&lt;/li&gt;
  &lt;li&gt;평가&lt;/li&gt;
&lt;/ol&gt;</content>

      
      
      
      
      

      <author>
          <name>Jaekwang Van</name>
        
        
      </author>

      

      
        <category term="machinelearning" />
      

      
        <summary type="html">분류(Classification)는 대표적인 지도학습(Supervised Learning) 방법의 하나이다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">시작하기 앞서</title>
      <link href="http://localhost:4000/ml-0intro_bk" rel="alternate" type="text/html" title="시작하기 앞서" />
      <published>2021-10-28T00:00:00+09:00</published>
      <updated>2021-10-28T00:00:00+09:00</updated>
      <id>http://localhost:4000/ml-0intro_bk</id>
      <content type="html" xml:base="http://localhost:4000/ml-0intro_bk">&lt;p&gt;이 글은 &lt;a href=&quot;https://www.gilbut.co.kr/book/view?bookcode=BN003058&amp;amp;keyword=%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EA%B5%90%EA%B3%BC%EC%84%9C&amp;amp;collection=GB_BOOK&quot;&gt;머신 러닝 교과서 with 파이썬, 사이킷런, 텐서플로(개정 3판)&lt;/a&gt; 를 직접 따라해보고 요약 및 정리한 글 입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/built/images/ml/2021-11-17-ml-intro-book.png&quot; alt=&quot;book&quot; /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Jaekwang Van</name>
        
        
      </author>

      

      
        <category term="machinelearning" />
      

      
        <summary type="html">이 글은 머신 러닝 교과서 with 파이썬, 사이킷런, 텐서플로(개정 3판) 를 직접 따라해보고 요약 및 정리한 글 입니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Chapter01 파이썬 기반의 머신러닝과 생태계의 이해 (3)</title>
      <link href="http://localhost:4000/ml-ch01-03" rel="alternate" type="text/html" title="Chapter01 파이썬 기반의 머신러닝과 생태계의 이해 (3)" />
      <published>2021-10-28T00:00:00+09:00</published>
      <updated>2021-10-28T00:00:00+09:00</updated>
      <id>http://localhost:4000/ml-ch01-03</id>
      <content type="html" xml:base="http://localhost:4000/ml-ch01-03">&lt;h2 id=&quot;03-넘파이&quot;&gt;03. 넘파이&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;넘파이(Numpy)는 머신러닝의 주요 알고리즘인 선형대수와 통계 기반 프로그램을 쉽게 작성 가능하도록 지원한다. 또한 C/C++ 등 Low Level 언어 기반의 호환 API를 제공한다.&lt;/p&gt;

&lt;p&gt;넘파이는 배열 기반의 연산은 물론 다양한 데이터 핸들링 기능을 제공한다.&lt;/p&gt;

&lt;h3 id=&quot;넘파이-ndarray-개요&quot;&gt;넘파이 ndarray 개요&lt;/h3&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# numpy 모듈 import
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;array1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;array1 type:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;array1 array 형태:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;array2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;array2 type:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;array2 array 형태:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;array3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;array3 type:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;array3 array 형태:&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[output]
array1 type: &amp;lt;class &apos;numpy.ndarray&apos;&amp;gt;
array1 array 형태: (3,)
array2 type: &amp;lt;class &apos;numpy.ndarray&apos;&amp;gt;
array2 array 형태: (2, 3)
array3 type: &amp;lt;class &apos;numpy.ndarray&apos;&amp;gt;
array3 array 형태: (1, 3)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;array1: {:0}차원, array2: {:1}차원, array3: {:2}차원&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content>

      
      
      
      
      

      <author>
          <name>Jaekwang Van</name>
        
        
      </author>

      

      
        <category term="machinelearning" />
      

      
        <summary type="html">03. 넘파이</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Chapter01 파이썬 기반의 머신러닝과 생태계의 이해 (2)</title>
      <link href="http://localhost:4000/ml-ch01-02" rel="alternate" type="text/html" title="Chapter01 파이썬 기반의 머신러닝과 생태계의 이해 (2)" />
      <published>2021-10-28T00:00:00+09:00</published>
      <updated>2021-10-28T00:00:00+09:00</updated>
      <id>http://localhost:4000/ml-ch01-02</id>
      <content type="html" xml:base="http://localhost:4000/ml-ch01-02">&lt;h2 id=&quot;02-파이썬-머신러닝-생태계를-구성하는-주요-패키지&quot;&gt;02. 파이썬 머신러닝 생태계를 구성하는 주요 패키지&lt;/h2&gt;
&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;머신러닝 패키지&lt;/li&gt;
  &lt;li&gt;행렬/선형대수/통계 패키지&lt;/li&gt;
  &lt;li&gt;데이터 핸들링&lt;/li&gt;
  &lt;li&gt;시각화&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;파이썬-머신러닝을-위한-sw-설치&quot;&gt;파이썬 머신러닝을 위한 S/W 설치&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Anaconda&lt;/li&gt;
  &lt;li&gt;파이썬 3.6이상&lt;/li&gt;
  &lt;li&gt;Visual Studio Code&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>Jaekwang Van</name>
        
        
      </author>

      

      
        <category term="machinelearning" />
      

      
        <summary type="html">02. 파이썬 머신러닝 생태계를 구성하는 주요 패키지</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Chapter01 파이썬 기반의 머신러닝과 생태계의 이해 (1)</title>
      <link href="http://localhost:4000/ml-ch01-01" rel="alternate" type="text/html" title="Chapter01 파이썬 기반의 머신러닝과 생태계의 이해 (1)" />
      <published>2021-10-28T00:00:00+09:00</published>
      <updated>2021-10-28T00:00:00+09:00</updated>
      <id>http://localhost:4000/ml-ch01-01</id>
      <content type="html" xml:base="http://localhost:4000/ml-ch01-01">&lt;h3 id=&quot;01-머신러닝의-개념&quot;&gt;01. 머신러닝의 개념&lt;/h3&gt;
&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;머신러닝의 개념은 다양하게 표현 가능하나, 일반적으로는 애플리케이션을 수정하지 않고도 데이터를 기반으로 패턴을 학습하고 결과를 예측하는 알고리즘 기법을 통칭한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;머신러닝을 이용하면 금융사기 거래 적발이나 스팸메일 분류 등 소프트웨어 코드만으로 해결하기 힘든 현실세계의 문제들을 손쉽게 해결 가능하다. 여러 복잡한 조건과 패턴을 스스로 인지하고 해결하는 것이다.&lt;/p&gt;

&lt;h4 id=&quot;머신러닝의-분류&quot;&gt;머신러닝의 분류&lt;/h4&gt;

&lt;p&gt;일반적으로 머신러닝은 지도학습(Supervised Learning)과 비지도 학습(Un-supervised Learning), 강화학습(Reinforcement Learning)으로 나뉜다.&lt;/p&gt;

&lt;h6 id=&quot;지도학습&quot;&gt;지도학습&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;분류&lt;/li&gt;
  &lt;li&gt;회귀&lt;/li&gt;
  &lt;li&gt;추천 시스템&lt;/li&gt;
  &lt;li&gt;시각/음성 감지/인지&lt;/li&gt;
  &lt;li&gt;텍스트 분석, NLP&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;비지도학습&quot;&gt;비지도학습&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;클러스터링&lt;/li&gt;
  &lt;li&gt;차원 축소&lt;/li&gt;
  &lt;li&gt;강화학습&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;데이터-전쟁&quot;&gt;데이터 전쟁&lt;/h4&gt;

&lt;p&gt;머신러닝에서 중요한 요소는 “데이터”와 “머신러닝 알고리즘”이 있다. 품질 좋은 데이터를 갖추지 못한다면 머신러닝 알고리즘이 좋아도 좋은 결과를 얻지 못하며, 품질 좋은 데이터를 갖추어도 알고리즘이 좋지 못하면 좋은 결과를 도출할 수 없다.&lt;/p&gt;

&lt;h4 id=&quot;파이썬과-r-기반의-머신러닝-비교&quot;&gt;파이썬과 R 기반의 머신러닝 비교&lt;/h4&gt;

&lt;p&gt;머신러닝 프로그램을 작성할 수 있는 대표적인 언어로 파이썬과 R이 있다. 물론 다른 언어들도 가능하지만 생산성이 떨어지고 생태계가 활발하지 않다.&lt;/p&gt;

&lt;p&gt;저자는&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;개발 언어에 익숙하지 않으나 통계 분석에 능한 현업 사용자에게는 R을 추천한다. R은 통계 분석에 특화되었으며 많은 사용자들이 생성하고 검증해온 다양한 패키지를 보유하고 있기 때문이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;하지만 이제 머신러닝을 시작하려는 사람은 R보다는 파이썬을 권한다. 그 이유로는, 파이썬은 오픈 소스 계열의 전폭적인 지원을 받고 있어 쉽고 뛰어난 개발 생산성을 지닌다. 또한 인터프리터 언어로 속도는 느리지만, 뛰어난 확장성, 유연성, 호환성으로 인해 서버, 네트워크, 시스템, IOT, 심지어 데스크톱까지 다양한 영역에서 사용되고 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;고 말하고 있다.&lt;/p&gt;

&lt;p&gt;뛰어난 성능의 머신러닝 기법 중 하나인 딥러닝의 프레임워크들이 파이썬 우선 정책으로 지원받고 있기 때문에 앞으로는 파이썬을 중심으로 머신러닝은 계속 발전할 것이다.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Jaekwang Van</name>
        
        
      </author>

      

      
        <category term="machinelearning" />
      

      
        <summary type="html">01. 머신러닝의 개념</summary>
      

      
      
    </entry>
  
</feed>
